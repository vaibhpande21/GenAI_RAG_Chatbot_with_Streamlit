# ğŸ“š GenAI RAG Chatbot with Streamlit  

[![Python](https://img.shields.io/badge/Python-3.9%2B-blue)](https://www.python.org/)  
[![Streamlit](https://img.shields.io/badge/Framework-Streamlit-brightgreen)](https://streamlit.io/)  
[![LangChain](https://img.shields.io/badge/Powered%20By-LangChain-orange)](https://www.langchain.com/)  
[![OpenAI](https://img.shields.io/badge/LLM-OpenAI%20GPT-red)](https://platform.openai.com/)  

---

## ğŸš€ Project Overview  
This project is a **Retrieval-Augmented Generation (RAG) Chatbot** built with **Streamlit**, **LangChain**, and **OpenAI GPT models**.  

It allows users to upload PDF documents, create vector embeddings, and then **ask natural language questions** to retrieve answers directly from the documents.  

âœ¨ **Key Features**  
- ğŸ“‚ Upload PDF files for context  
- ğŸ§  Vector embeddings powered by FAISS  
- ğŸ’¬ Chat interface for interactive Q&A  
- âš¡ Retrieval-Augmented Generation for precise answers  
- ğŸ¨ User-friendly Streamlit UI  

---

## ğŸ› ï¸ Tech Stack  
- **Frontend/UI**: [Streamlit](https://streamlit.io/)  
- **LLM**: OpenAI GPT (via `langchain_openai`)  
- **Embeddings & Retrieval**: FAISS + LangChain  
- **Document Parsing**: PyPDF  
- **Environment Management**: Python `venv`  

---

## ğŸ“‚ Project Structure  
```plaintext
genai-rag-chatbot/  
â”‚â”€â”€ app.py              # Streamlit chatbot app  
â”‚â”€â”€ requirements.txt    # Python dependencies  
â”‚â”€â”€ .env.example        # Sample environment variables   
â”‚â”€â”€ README.md           # Project documentation  
â”‚â”€â”€ LICENSE             # Open-source license (MIT recommended)
```
---

## âš™ï¸ Setup & Installation


1ï¸âƒ£ Clone the repository
```bash
git clone https://github.com/vaibhavpande21/genai-rag-chatbot.git
cd genai-rag-chatbot
```

2ï¸âƒ£ Create a virtual environment
```bash
python -m venv .venv  
source .venv/bin/activate   # Mac/Linux  
.venv\Scripts\activate      # Windows
```

3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```

4ï¸âƒ£ Set up environment variables
```bash
Create a .env file in the project root:
OPENAI_API_KEY=openai_api_key
```

â–¶ï¸ Running the App
Start the Streamlit app:
```bash
streamlit run app.py
```
The app will open in your browser at:
```bash
ğŸ‘‰ http://localhost:8501
```

ğŸ“– How It Works:

1. Upload a PDF file.
2. The app extracts text, chunks it, and creates vector embeddings with FAISS.
3. When you enter a question, the system:
   a.) Retrieves the most relevant chunks.
   b.) Passes them as context to the OpenAI LLM.
   c.) Generates a precise, context-aware answer.
